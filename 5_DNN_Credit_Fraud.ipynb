{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (227845, 28)\n",
      "y_train shape: (227845,)\n",
      "X_test shape: (56962, 28)\n",
      "y_test shape: (56962,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,1:29]\n",
    "Y = df.iloc[:, 30]\n",
    "\n",
    "X = normalize(X)\n",
    "y = np.array(Y)\n",
    "y = y.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(X_train),\n",
    "        torch.from_numpy(y_train)\n",
    "    ),\n",
    "    batch_size=len(X_train), shuffle=True\n",
    "    \n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.from_numpy(X_test),\n",
    "        torch.from_numpy(y_test)\n",
    "    ),\n",
    "    batch_size=len(X_test), shuffle=False\n",
    "    \n",
    ")\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": trainloader,\n",
    "    \"validation\": testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28, 340)\n",
    "        self.fc2 = nn.Linear(340, 220)\n",
    "        self.fc3 = nn.Linear(220, 200)\n",
    "        self.fc4 = nn.Linear(200, 70)\n",
    "        self.fc5 = nn.Linear(70, 10)\n",
    "        self.fc6 = nn.Linear(10, 2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(F.relu(self.fc5(x)))\n",
    "        x = F.log_softmax(self.fc6(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=28, out_features=340, bias=True)\n",
       "  (fc2): Linear(in_features=340, out_features=220, bias=True)\n",
       "  (fc3): Linear(in_features=220, out_features=200, bias=True)\n",
       "  (fc4): Linear(in_features=200, out_features=70, bias=True)\n",
       "  (fc5): Linear(in_features=70, out_features=10, bias=True)\n",
       "  (fc6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "    output = model(inputs)\n",
    "    return torch.argmax(output,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Epoch [1/40], Iter [1] Loss: 0.0569 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [2/40], Iter [1] Loss: 0.0705 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [3/40], Iter [1] Loss: 0.0761 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [4/40], Iter [1] Loss: 0.0727 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [5/40], Iter [1] Loss: 0.0699 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [6/40], Iter [1] Loss: 0.0606 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [7/40], Iter [1] Loss: 0.0520 Training Accuracy: 0.9965\n",
      "---------------------------------------------------------\n",
      "Epoch [8/40], Iter [1] Loss: 0.0450 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [9/40], Iter [1] Loss: 0.0374 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [10/40], Iter [1] Loss: 0.0340 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [11/40], Iter [1] Loss: 0.0302 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [12/40], Iter [1] Loss: 0.0268 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [13/40], Iter [1] Loss: 0.0250 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [14/40], Iter [1] Loss: 0.0208 Training Accuracy: 0.9965\n",
      "---------------------------------------------------------\n",
      "Epoch [15/40], Iter [1] Loss: 0.0193 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [16/40], Iter [1] Loss: 0.0163 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [17/40], Iter [1] Loss: 0.0158 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [18/40], Iter [1] Loss: 0.0141 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [19/40], Iter [1] Loss: 0.0125 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [20/40], Iter [1] Loss: 0.0117 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [21/40], Iter [1] Loss: 0.0105 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [22/40], Iter [1] Loss: 0.0096 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [23/40], Iter [1] Loss: 0.0094 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [24/40], Iter [1] Loss: 0.0090 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [25/40], Iter [1] Loss: 0.0089 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [26/40], Iter [1] Loss: 0.0087 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [27/40], Iter [1] Loss: 0.0088 Training Accuracy: 0.9965\n",
      "---------------------------------------------------------\n",
      "Epoch [28/40], Iter [1] Loss: 0.0090 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [29/40], Iter [1] Loss: 0.0085 Training Accuracy: 0.9965\n",
      "---------------------------------------------------------\n",
      "Epoch [30/40], Iter [1] Loss: 0.0080 Training Accuracy: 0.9967\n",
      "---------------------------------------------------------\n",
      "Epoch [31/40], Iter [1] Loss: 0.0076 Training Accuracy: 0.9964\n",
      "---------------------------------------------------------\n",
      "Epoch [32/40], Iter [1] Loss: 0.0072 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [33/40], Iter [1] Loss: 0.0070 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [34/40], Iter [1] Loss: 0.0070 Training Accuracy: 0.9966\n",
      "---------------------------------------------------------\n",
      "Epoch [35/40], Iter [1] Loss: 0.0069 Training Accuracy: 0.9977\n",
      "---------------------------------------------------------\n",
      "Epoch [36/40], Iter [1] Loss: 0.0066 Training Accuracy: 0.9979\n",
      "---------------------------------------------------------\n",
      "Epoch [37/40], Iter [1] Loss: 0.0062 Training Accuracy: 0.9979\n",
      "---------------------------------------------------------\n",
      "Epoch [38/40], Iter [1] Loss: 0.0058 Training Accuracy: 0.9979\n",
      "---------------------------------------------------------\n",
      "Epoch [39/40], Iter [1] Loss: 0.0056 Training Accuracy: 0.9979\n",
      "---------------------------------------------------------\n",
      "Epoch [40/40], Iter [1] Loss: 0.0056 Training Accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "loss1 = []\n",
    "train_acc = []\n",
    "\n",
    "Epoch = 20\n",
    "\n",
    "for epoch in range(Epoch):\n",
    "    print('---------------------------------------------------------')\n",
    "    acc = 0\n",
    "    train_acc1=0\n",
    "    \n",
    "    for i, (features, labels) in enumerate(trainloader):\n",
    "        \n",
    "        #load dataset\n",
    "        features = Variable(features).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        optimizer.zero_grad() ## set grads to 0\n",
    "        features = features.float()\n",
    "        \n",
    "        #Get model training predictions\n",
    "        outputs = model(features)\n",
    "        \n",
    "        #Estimate loss value\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        #Perform backpropragation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Start over moving along solutions space\n",
    "        optimizer.step()\n",
    "        \n",
    "        # After training epoch, check accuracy\n",
    "        if (i+1) % len(trainloader) == 0:\n",
    "            y_pred = predict(\n",
    "                model, \n",
    "                torch.from_numpy(X_train).float().to(device)\n",
    "            )\n",
    "            acc = np.mean(y_train == np.array(y_pred.cpu()))\n",
    "            \n",
    "            train_acc1 = acc/len(trainloader)\n",
    "            train_acc.append(train_acc1)\n",
    "            loss1.append(loss.data)\n",
    "            \n",
    "            print (f'Epoch [{epoch+1}/{Epoch}], Iter [{i+1}] Loss: {loss.data:.4f} Training Accuracy: {train_acc1:.4f}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracies and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_loss = np.array(loss1[0].cpu())\n",
    "\n",
    "for i in range(len(loss1)):\n",
    "    np_loss = np.append(np_loss, loss1[i].cpu())\n",
    "    \n",
    "np_acc = train_acc[0]\n",
    "for i in range(len(train_acc)):\n",
    "    np_acc = np.append(np_acc, train_acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfgElEQVR4nO3de3wU9b3/8dcnISFWkGsUJCCoaIWYxBg9pVistSKiR+qt4K1qbdG21tYLLbUe9cfx93hQ++ip0qrVXyvaHgmg/bVyFOUcL/VuNSgXgZ8lAmq4GySiFTDw+f0xs8lm2U02YcNmh/fz8ZjHzszOzH52CO/57ndnZ8zdERGR3JeX7QJERCQzFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnTJeWaWb2afmNmQTC4rkmtM56HLvmZmn8RNfgHYAewKp69y94f3fVV7z8xuB0rc/fJs1yL7p27ZLkD2P+7eIzZuZmuA77j706mWN7Nu7t64L2oTyWXqcpEux8xuN7M5ZlZtZtuAS8xslJm9ZmZbzWy9mc0ws4Jw+W5m5mY2NJz+z/D5J81sm5m9ambD2rts+PwZZvYPM2sws9+Y2ctmdnkH3tNIM3s+rH+pmZ0Z99xZZrYifP06M7sunH+wmc0P19liZi90dJ/K/kGBLl3VOcAsoBcwB2gEfgT0B0YD44CrWln/IuDfgL7A+8C/t3dZMzsYmAtMCV93NXBie9+ImRUCjwNPAMXAdcAcMzsyXGQmcKW79wTKgOfD+VOAVeE6A8IaRVJSoEtX9ZK7/5e773b3z9z9DXf/u7s3uvsq4H7g5FbWf9Tda9z9c+BhoKIDy54FLHL3x8Lnfg182IH3MhooBH7p7p+H3UtPApPC5z8HRphZT3ff4u5vxs0/FBji7jvd/fk9tiwSR4EuXdUH8RNm9kUze8LMNpjZx8A0glZzKhvixv8J9Ei1YCvLHhpfhwdnENSlUXuiQ4H3veUZCO8Bg8Lxc4CzgffN7G9m9i/h/Onhcs+Y2btmNqUDry37EQW6dFWJp1/dB7wNHOnuBwG3ANbJNawHSmITZmY0h3B7rAMGh+vHDAHWAoSfPM4GDibompkdzv/Y3a9z96HAN4Cfmllrn0pkP6dAl1zRE2gAPjWzY2i9/zxTHgcqzexfzawbQR9+cRvr5JtZUdzQHXiF4DuAG8yswMy+BowH5prZAWZ2kZkdFHbrbCM8hTN83SPCA0FDOH9X8pcVUaBL7rgBuIwg8O4j+KK0U7n7RmAi8B9APXAE8BbBefOpXAJ8Fje84+47gH8FJhD0wc8ALnL3f4TrXAa8F3YlXQlcGs4/GngW+AR4GbjL3V/K2BuUyNEPi0TSZGb5BN0n57v7i9muRySRWugirTCzcWbWK+w6+TeCrpPXs1yWSFIKdJHWnURwLviHBOe+fyPsQhHpctTlIiISEWqhi4hERNYuztW/f38fOnRotl5eRCQnLVy48EN3T3r6bNYCfejQodTU1GTr5UVEcpKZvZfqOXW5iIhEhAJdRCQiFOgiIhGhQBcRiQgFuohIRLQZ6Gb2gJltMrO3Uzxv4S28as1siZlVZr5MERFpSzot9AcJfvKcyhnA8HCYDNy792WJiEh7tXkeuru/ELuhbgoTgD+Gd2N5zcx6m9lAd1+foRpbeP99ePfdvduGtXJbhPZcCSG2nfjtJW472XNme65rFrx2bNi9u+V0W9tMrL+t99Haesm2Eas5sfZU8+JfI/59pFtfqvfTnvXa+56SvZ/Wtp1siNfWfkn3vabablt1J3uddLed+DrJ/jbj/0bNIC+v+TF+PHH91vZZe/7/uUNjI+zYEQzbt+85vnt3yzrja2+PTFwhJf7f46yz4IQT9n6biTLxw6JBtLxdWF04b49AN7PJBK14hgwZ0qEXmzMHfvKTDq0qItJhrR3k25J4QBg4sOsGerK3mfR45u73E9zcl6qqqg4d8yZNghPbfd/1+BraXiadf7hkLZzWWhuttRbjWznxrZpkLa9U20z1SaC12hPXTdWaTNXCTjUv8T3FbzOdlmpibcnqS0drLeTWWozp/o201kJO5xNCqu229phu3cn+FtPddrLXSfzbTNYCj28NJ46359NQe4IzPx+KiqB79z0fCwuD51PVHEWZCPQ6YHDcdAnBTQA6xeDBwSAiIi1l4rTFecC3wrNdvgQ0dFb/uYiIpNZmC93MqoGvAv3NrA64FSgAcPffAfMJbnhbC/wTuKKzihURkdTSOcvlwjaed+AHGatIREQ6RL8UFRGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQi0gp0MxtnZu+YWa2ZTU3y/BAze87M3jKzJWY2PvOliohIa9oMdDPLB+4GzgBGABea2YiExW4G5rr7ccAk4J5MFyoiIq1Lp4V+IlDr7qvcfScwG5iQsIwDB4XjvYB1mStRRETSkU6gDwI+iJuuC+fFuw24xMzqgPnAD5NtyMwmm1mNmdVs3ry5A+WKiEgq6QS6JZnnCdMXAg+6ewkwHviTme2xbXe/392r3L2quLi4/dWKiEhK6QR6HTA4brqEPbtUrgTmArj7q0AR0D8TBYqISHrSCfQ3gOFmNszMCgm+9JyXsMz7wKkAZnYMQaCrT0VEZB9qM9DdvRG4BlgArCA4m2WZmU0zs7PDxW4Avmtmi4Fq4HJ3T+yWERGRTtQtnYXcfT7Bl53x826JG18OjM5saSIi0h76paiISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCLSCnQzG2dm75hZrZlNTbHMN81suZktM7NZmS1TRETa0q2tBcwsH7gbOA2oA94ws3nuvjxumeHAz4DR7v6RmR3cWQWLiEhy6bTQTwRq3X2Vu+8EZgMTEpb5LnC3u38E4O6bMlumiIi0JZ1AHwR8EDddF86LdxRwlJm9bGavmdm4TBUoIiLpabPLBbAk8zzJdoYDXwVKgBfNrNTdt7bYkNlkYDLAkCFD2l2siIiklk4LvQ4YHDddAqxLssxj7v65u68G3iEI+Bbc/X53r3L3quLi4o7WLCIiSaQT6G8Aw81smJkVApOAeQnL/BU4BcDM+hN0wazKZKEiItK6Nrtc3L3RzK4BFgD5wAPuvszMpgE17j4vfG6smS0HdgFT3L2+MwsX2Z98/vnn1NXVsX379myXIvtIUVERJSUlFBQUpL2OuSd2h+8bVVVVXlNTk5XXFsk1q1evpmfPnvTr1w+zZF9rSZS4O/X19Wzbto1hw4a1eM7MFrp7VbL19EtRkRywfft2hfl+xMzo169fuz+RKdBFcoTCfP/SkX9vBbqItKm+vp6KigoqKioYMGAAgwYNapreuXNnWtu44ooreOedd1pd5u677+bhhx/ORMkAbNy4kW7duvGHP/whY9vsytSHLpIDVqxYwTHHHJPtMgC47bbb6NGjBzfeeGOL+e6Ou5OX13XaiTNmzOCRRx6he/fuPP300532Oo2NjXTrls7Peton2b+7+tBFpFPU1tZSWlrK1VdfTWVlJevXr2fy5MlUVVUxcuRIpk2b1rTsSSedxKJFi2hsbKR3795MnTqV8vJyRo0axaZNwdVCbr75Zu68886m5adOncqJJ57I0UcfzSuvvALAp59+ynnnnUd5eTkXXnghVVVVLFq0KGl91dXV3HnnnaxatYoNGzY0zX/iiSeorKykvLycsWPHArBt2zYuu+wyjj32WMrKyvjrX//aVGvM7Nmz+c53vgPAJZdcwg033MApp5zCTTfdxGuvvcaoUaM47rjjGD16NCtXrgSCsL/uuusoLS2lrKyMe+65hwULFnDBBRc0bffJJ5/km9/85l7/e2T+kCIinerHP4YU+dVhFRUQ5mi7LV++nJkzZ/K73/0OgOnTp9O3b18aGxs55ZRTOP/88xkxYkSLdRoaGjj55JOZPn06119/PQ888ABTp+55IVd35/XXX2fevHlMmzaNp556it/85jcMGDCAP//5zyxevJjKysqkda1Zs4aPPvqI448/nvPPP5+5c+dy7bXXsmHDBr73ve/x4osvcthhh7FlyxYg+ORRXFzM0qVLcXe2bt2adLvx3n33XZ555hny8vJoaGjgpZdeIj8/n6eeeoqbb76ZOXPmcO+997Ju3ToWL15Mfn4+W7ZsoXfv3lx77bXU19fTr18/Zs6cyRVXXNHeXb8HtdBFZK8cccQRnHDCCU3T1dXVVFZWUllZyYoVK1i+fPke6xxwwAGcccYZABx//PGsWbMm6bbPPffcPZZ56aWXmDRpEgDl5eWMHDky6brV1dVMnDgRgEmTJlFdXQ3Aq6++yimnnMJhhx0GQN++fQF4+umn+cEPfgAEX0j26dOnzfd+wQUXNHUxbd26lXPPPZfS0lJuvPFGli1b1rTdq6++mvz8/KbXy8vL46KLLmLWrFls2bKFhQsXNn1S2BtqoYvkmI62pDvLgQce2DS+cuVK7rrrLl5//XV69+7NJZdckvTUu8LCwqbx/Px8Ghsbk267e/fueyyT7vd+1dXV1NfX89BDDwGwbt06Vq9ejbsnPYMk2fy8vLwWr5f4XuLf+89//nNOP/10vv/971NbW8u4ceNSbhfg29/+Nueddx4AEydObAr8vaEWuohkzMcff0zPnj056KCDWL9+PQsWLMj4a5x00knMnTsXgKVLlyb9BLB8+XJ27drF2rVrWbNmDWvWrGHKlCnMnj2b0aNH8+yzz/Lee+8BNHW5jB07lt/+9rdAEMIfffQReXl59OnTh5UrV7J7927+8pe/pKyroaGBQYOCC9E++OCDTfPHjh3Lvffey65du1q83uDBg+nfvz/Tp0/n8ssv37udElKgi0jGVFZWMmLECEpLS/nud7/L6NGjM/4aP/zhD1m7di1lZWX86le/orS0lF69erVYZtasWZxzzjkt5p133nnMmjWLQw45hHvvvZcJEyZQXl7OxRdfDMCtt97Kxo0bKS0tpaKighdffBGAX/ziF4wbN45TTz2VkpKSlHX99Kc/ZcqUKXu856uuuooBAwZQVlZGeXl508EI4KKLLmLYsGEcddRRe7VPYnTaokgO6EqnLWZbY2MjjY2NFBUVsXLlSsaOHcvKlSs75bTBznb11VczatQoLrvssqTPt/e0xdzbAyKyX/vkk0849dRTaWxsxN257777cjLMKyoq6NOnDzNmzMjYNnNvL4jIfq13794sXLgw22XstVTnzu8N9aGLiESEAl1EJCIU6CIiEaFAFxGJCAW6iLQpFy+fG7sY2P5EZ7mISJv69evXFI4dvXzuzJkz23yd2LVUpGPUQheRDuvql89N9NlnnzVdIreyspIXXngBCC4hcMIJJ1BRUUFZWRmrVq1i27ZtnHHGGZSXl1NaWsqjjz6ayV3XKdRCF8k1Xez6uV318rnJzJgxg8LCQpYuXcqyZcsYP348K1eu5J577uHGG29k4sSJ7NixA3fnscceY+jQoTz55JNNNXd1aqGLyF7pqpfPTeall17i0ksvBWDkyJEceuih1NbW8uUvf5nbb7+dO+64gw8++ICioiLKysp46qmnmDp1Ki+//PIe14vpitRCF8k1Xez6uV318rnJpFr30ksvZdSoUTzxxBOcdtppPPTQQ4wZM4aamhrmz5/PlClTOOuss7jppps6/Nr7glroIpIxXeXyuamMGTOm6SyaFStWsH79eo488khWrVrFkUceyY9+9CPOPPNMlixZwtq1a+nRoweXXnop119/PW+++WbG30umqYUuIhkTf/ncww8/vNMun/utb32LsrIyKisrk14+N+b000+noKAAgK985Ss88MADXHXVVRx77LEUFBTwxz/+kcLCQmbNmkV1dTUFBQUceuih3H777bzyyitMnTqVvLw8CgsLm74j6Mp0+VyRHKDL5zaL0uVz26LL54pIpEXl8rmdQXtBRHJKVC6f2xn0paiISEQo0EVyRLa+75Ls6Mi/twJdJAcUFRVRX1+vUN9PuDv19fUUFRW1a720+tDNbBxwF5AP/N7dp6dY7nzgEeAEd9cpLCIZUlJSQl1dHZs3b852KbKPFBUVUVJS0q512gx0M8sH7gZOA+qAN8xsnrsvT1iuJ3At8Pd2VSAibSooKGDYsGHZLkO6uHS6XE4Eat19lbvvBGYDE5Is9+/AHcCev/MVEZFOl06gDwI+iJuuC+c1MbPjgMHu/nhrGzKzyWZWY2Y1+ugoIpJZ6QS6JZnX9M2MmeUBvwZuaGtD7n6/u1e5e1VxcXH6VYqISJvSCfQ6YHDcdAmwLm66J1AK/M3M1gBfAuaZWdKfpoqISOdIJ9DfAIab2TAzKwQmAfNiT7p7g7v3d/eh7j4UeA04W2e5iIjsW20Gurs3AtcAC4AVwFx3X2Zm08zs7M4uUERE0pPWeejuPh+YnzDvlhTLfnXvyxIRkfbSL0VFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiYi0At3MxpnZO2ZWa2ZTkzx/vZktN7MlZvaMmR2W+VJFRKQ1bQa6meUDdwNnACOAC81sRMJibwFV7l4GPArckelCRUSkdem00E8Eat19lbvvBGYDE+IXcPfn3P2f4eRrQElmyxQRkbakE+iDgA/ipuvCealcCTyZ7Akzm2xmNWZWs3nz5vSrFBGRNqUT6JZknidd0OwSoAr4ZbLn3f1+d69y96ri4uL0qxQRkTZ1S2OZOmBw3HQJsC5xITP7OvBz4GR335GZ8kREJF3ptNDfAIab2TAzKwQmAfPiFzCz44D7gLPdfVPmyxQRkba0Geju3ghcAywAVgBz3X2ZmU0zs7PDxX4J9AAeMbNFZjYvxeZERKSTpNPlgrvPB+YnzLslbvzrGa5LRETaSb8UFRGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRIQCXUQkIhToIiIRoUAXEYkIBbqISESkdQu6SProI1i5Mhj+8Y/m8W3b4OCD4ZBD9nw85BDo1y8Y+vSB/PxsvwsRkSb7T6DX1UF1NcybBytWQH1983NmcNhhMHw4DB0KmzbB22/Dxo1B8KfSu3cQ7n37Bo8DB8KXvwxjxgTbMuv0tyUiEhPtQN+6FR59FB5+GJ5/Htzh+OPh3HPhqKOC0B0+HA4/HIqKkm9j507YvDkI+Y0bgwNBfT1s2dLysb4eFi6EmTOD9QYODIJ9zBg4+WQYMUIBLyKdKvcCfccO2L499fO7dsHf/haE+OOPB4E8fDjceitcdFEw3h6FhTBoUDC0xR3eeQdeeCE4gDz/PMyZEzzXvz+MHh204EeNgqoqOOCA9tUiItIKc/esvHBVVZXX1NS0f8Vf/hJ+8pO2lzvkEJg0CS6+OAjPbLSO3WH16uZwf+WVoJ8eoFs3OO645oAfNQoGD1YrXkRaZWYL3b0q6XM5F+g1NfDii60vM3IkfO1rQWh2NZs3w2uvBeH+6qvw+uvw2WfBc/36QVkZlJc3DyNGQPfu2a1ZRLqMaAV61Hz+OSxZEoT84sXBsHRpc8jn58MXvwgVFUH/f1VV0LLv0SO7dYtIVrQW6F2wCbufKSgIgvr445vn7doFtbXNAb9kCTz3XPC9AATdMkcfHYR7bN3DDw9OrywoyM77EJGsUws9l2zYEJxJs3Bh0PW0cCGsW9dymb59m8+Zj50/P2BAMAwc2DwUF0OeflcmkmvUQo+KAQPgzDODIWbDBnjzTfjgg+C0yvjhrbeC0y0bGvbcVn5+EPYDBwbbjR0EEoeDD4ZevdTyF8kBCvRcN2AAjB/f+jKffRYE//r1LYfYvHXrmsO/sTH5NgoLg377Hj2gZ8/m8d69oaSk5TB4cHCgKCzM/PsVkZQU6PuDAw6AYcOCoTW7dwe/jI1v5W/aFFwO4ZNPmh9jw7ZtsHYtLFgQTMczC1r4ffoEr/+FL+w5HHhgcGZP//7BkDius3tE2kWBLs3y8pqvVTNiRPvWbWgILq+QODQ0wD//GQwNDcEngth07KCQSmFh0DUUG7p1azn+hS80f1Lo0SM4QMSPtzZ07x50I8UP3boFj4WFwS+HCwv1uwDJKWkFupmNA+4C8oHfu/v0hOe7A38EjgfqgYnuviazpUqX1qtXMIwc2b71du5svnTChx+2HD75JDjjJzY0NrYcjx0UPv006D6Kjcc+QaTqPmqPoqKWwwEHBAeDwsLmIXYQiA15ecFglvwxL6/lgSp+iP+iOnYwiT+omLXcXuIAwQ/aYic7xD8mDrt3t1w22UEz3cf49xUbjx/i31/i+40fku2zVPsh2XiitupKfC7HD+BtBrqZ5QN3A6cBdcAbZjbP3ZfHLXYl8JG7H2lmk4BfABM7o2CJmMLC5jNvMm3nziDgkw07dgS/AYgfGhuDx507my8xsX178B1EbDw2xJbbuTM4eMTGd+5sDspkj7Eh/kAVPyQL4s4UH5i7d3fua+UCs+QHnvgDXWxIdkBNdoCN33bMrbfCxMxHZDot9BOBWndfFdRks4EJQHygTwBuC8cfBX5rZubZOidSBJpbzH36ZLuSzEnVwo4N8a3ZxJZtW4ET22biJ6HE6cTHxsaWB6vEIbZu4oEsNp14wEs8CMZqi68zcV5r+yr2GsnqShxPVmfip8P4g29rQ2It8TrpbzKdQB8EfBA3XQf8S6pl3L3RzBqAfsCH8QuZ2WRgMsCQIUM6WLLIfiw+iDN9Pf5Y61TX+c9Z6fyyJFmnUuKhMZ1lcPf73b3K3auKi4vTqU9ERNKUTqDXAYPjpkuAdamWMbNuQC9gSyYKFBGR9KQT6G8Aw81smJkVApOAeQnLzAMuC8fPB55V/7mIyL7VZh962Cd+DbCA4LTFB9x9mZlNA2rcfR7wB+BPZlZL0DKf1JlFi4jIntI6D93d5wPzE+bdEje+Hbggs6WJiEh76HJ7IiIRoUAXEYkIBbqISERk7QYXZrYZeK+Dq/cn4UdLXYTqah/V1X5dtTbV1T57U9dh7p70hzxZC/S9YWY1qe7YkU2qq31UV/t11dpUV/t0Vl3qchERiQgFuohIRORqoN+f7QJSUF3to7rar6vWprrap1Pqysk+dBER2VOuttBFRCSBAl1EJCJyLtDNbJyZvWNmtWY2Ndv1xJjZGjNbamaLzKwmi3U8YGabzOztuHl9zex/zGxl+LjPb+GToq7bzGxtuM8Wmdn4LNQ12MyeM7MVZrbMzH4Uzs/qPmulrqzuMzMrMrPXzWxxWNf/CucPM7O/h/trTnhl1q5Q14Nmtjpuf1Xsy7ri6ss3s7fM7PFwunP2l7vnzEBwtcd3gcOBQmAxMCLbdYW1rQH6d4E6xgCVwNtx8+4ApobjU4FfdJG6bgNuzPL+GghUhuM9gX8AI7K9z1qpK6v7jOBmNj3C8QLg78CXgLnApHD+74DvdZG6HgTOz+bfWFjT9cAs4PFwulP2V6610Jvub+ruO4HY/U0l5O4vsOfNRSYAD4XjDwHf2KdFkbKurHP39e7+Zji+DVhBcEvFrO6zVurKKg98Ek4WhIMDXyO4nzBkZ3+lqivrzKwEOBP4fThtdNL+yrVAT3Z/06z/kYcc+G8zWxjeO7UrOcTd10MQFMDBWa4n3jVmtiTsksnq3ZzNbChwHEHrrsvss4S6IMv7LOw+WARsAv6H4FPzVndvDBfJyv/LxLrcPba//ne4v35tZt33dV3AncBPgPCO1/Sjk/ZXrgV6WvcuzZLR7l4JnAH8wMzGZLugHHAvcARQAawHfpWtQsysB/Bn4Mfu/nG26kiUpK6s7zN33+XuFQS3ozwROCbZYvu2qj3rMrNS4GfAF4ETgL7AT/dlTWZ2FrDJ3RfGz06yaEb2V64Fejr3N80Kd18XPm4C/kLwh95VbDSzgQDh46Ys1wOAu28M/xPuBv4PWdpnZlZAEJoPu/v/DWdnfZ8lq6ur7LOwlq3A3wj6qnuH9xOGLP+/jKtrXNh15e6+A5jJvt9fo4GzzWwNQRfx1wha7J2yv3It0NO5v+k+Z2YHmlnP2DgwFni79bX2qfh7vl4GPJbFWprEAjN0DlnYZ2F/5h+AFe7+H3FPZXWfpaor2/vMzIrNrHc4fgDwdYL+/ecI7icM2dlfyer6f3EHZSPop96n+8vdf+buJe4+lCCvnnX3i+ms/ZXtb3878G3xeIJv/N8Ffp7tesKaDic442YxsCybdQHVBB/FPyf4RHMlQZ/dM8DK8LFvF6nrT8BSYAlBgA7MQl0nEXzcXQIsCofx2d5nrdSV1X0GlAFvha//NnBLOP9w4HWgFngE6N5F6no23F9vA/9JeCZMNgbgqzSf5dIp+0s//RcRiYhc63IREZEUFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYj4/wAwpKduVqkFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(np_acc, color=\"blue\", label=\"Training Accuracy\")\n",
    "plt.plot(np_loss, color=\"red\", label=\"Training Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance in Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.998156665847407\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(model, torch.from_numpy(X_test).float().to(device))\n",
    "acc = np.mean(y_test == np.array(y_pred.cpu()))\n",
    "print('Test accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision / Recall / F1 Scores using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00     56876\n",
      "     Class 1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Class 0', 'Class 1']\n",
    "print(classification_report(y_test, np.array(y_pred.cpu()), target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best measure to use for evaluating the credit default model performance is precision and recall of minoritary class. This notebook is just to show the use of pytorch and GPU tensor in classification model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-study]",
   "language": "python",
   "name": "conda-env-.conda-study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
